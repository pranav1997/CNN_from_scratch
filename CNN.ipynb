{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed=10\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_H=32  #Height of image\n",
    "n_W=32  #Width of image\n",
    "n_C=1   #number of colour channels\n",
    "f_H=3   #Height of filters\n",
    "f_W=3   #Width of filters\n",
    "n_f=4   #number of filters\n",
    "lr=0.1  #learning_rate\n",
    "n_F=10  #Number of neurons in final layer\n",
    "\n",
    "pad_size = 1\n",
    "stride = 2\n",
    "\n",
    "#New height and width after\n",
    "n_H2 = int(np.floor((n_H-f_H+2*pad_size)/stride)) + 1\n",
    "n_W2 = int(np.floor((n_W-f_W+2*pad_size)/stride)) + 1\n",
    "\n",
    "cache = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padding(X, pad_size,pad_variable=0):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad_size -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    pad_variable -- the number to pad with(default 0)\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad,n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_pad = np.pad(X,((0,0),(pad_size,pad_size),(pad_size,pad_size),(0,0)),'constant',constant_values = pad_variable)\n",
    "    \n",
    "    return X_pad\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"\n",
    "    Implements ReLU activation funtion for array x\n",
    "    \"\"\"\n",
    "    xf = (x>0).astype(np.int)\n",
    "    return(np.multiply(xf,x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv_single_step(X_slice,W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W[] on a single slice (slice) from the image\n",
    "    \n",
    "    Arguments:\n",
    "    X_slice -- slice of input data of shape (f_H, f_W, n_C)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f_H, f_W, n_C, n_f)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1, n_f)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "    s = np.multiply(X_slice,W)\n",
    "    A = np.sum(s)\n",
    "    A = A + float(b)\n",
    "    Z = relu(A)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_forward(X,cache):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    X -- Input image data, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache\n",
    "    \n",
    "    cache imports:\n",
    "    W -- Weights, numpy array of shape (f_H, f_W,n_C,n_f)\n",
    "    b -- Biases, numpy array of shape (1,1,1, n_f)\n",
    "     \n",
    "    cache saves:\n",
    "    X_pad -- padded \n",
    "    Z -- conv output, numpy array of shape (m, n_H2, n_W2, n_f)\n",
    "    R_Z -- bool which stores whether Z>0 or not, which is basically derivative of ReLU\n",
    "    \"\"\"\n",
    "    \n",
    "    W = cache['W']\n",
    "    b = cache['b']\n",
    "    m = X.shape[0]\n",
    "\n",
    "    \n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    Z = np.zeros((m,n_H2,n_W2,n_f))\n",
    "    # Initialize R_Z\n",
    "    R_Z =np.zeros((m,n_H2,n_W2,n_f))  \n",
    "    # Create padded image\n",
    "    X_pad = padding(X,1,0)\n",
    "    \n",
    "    for i in range(m):                               # loop over the batch of training examples\n",
    "        Xc = X_pad[i]                               # Select ith training example's padded image\n",
    "        for h in range(n_H2):                           # loop over vertical axis of the output volume\n",
    "            for w in range(n_W2):                       # loop over horizontal axis of the output volume\n",
    "                for c in range(n_f):                  # loop over channels (= #filters) of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start+f_H\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start+f_W\n",
    "                    \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell)\n",
    "                    X_slice = Xc[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron\n",
    "#                     print(\"******For c=\",c,\" ******\")\n",
    "#                     print(X_slice.shape)\n",
    "#                     print(W[:,:,:,c].shape)\n",
    "#                     print(b[:,:,:,c].shape)\n",
    "                    Z[i, h, w, c] = conv_single_step(X_slice,W[:,:,:,c],b[:,:,:,c])\n",
    "                    R_Z[i, h, w, c] = int(Z[i, h, w ,c]>0)\n",
    "                    \n",
    "                                        \n",
    "    assert(Z.shape == (m, n_H2, n_W2, n_f))\n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache['Z']=Z\n",
    "    cache['X_pad']=X_pad\n",
    "    cache['R_Z']=R_Z\n",
    "    print(\" Convolutional forward pass done\")\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(cache):\n",
    "    \"\"\"\n",
    "    Implements the fully connected layer\n",
    "    \n",
    "    Cache imports:\n",
    "    Z -- output activations of the previous layer, numpy array of shape (m, n_H2, n_W2, n_f)\n",
    "    W2 -- Weights, numpy array of shape (n_H2,n_W2,n_f,n_F)\n",
    "    b2 -- Biases, numpy array of shape (1,1,1,n_F)\n",
    "    \n",
    "    cache saves:\n",
    "    S -- Exponential sum(over all outputs) for every image of shape (m)\n",
    "    Z2 -- Output from fully connected layer after softmax of shape(m,n_F)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    W2=cache['W2']\n",
    "    b2=cache['b2']\n",
    "    Z=cache['Z']\n",
    "    m = Z.shape[0] \n",
    "    #initializing output activations\n",
    "    Z2 = np.zeros((m,n_F))\n",
    "    \n",
    "    S = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        for c in range(n_f):\n",
    "            for a in range(n_F):\n",
    "                A = np.multiply(Z[i,:,:,c],W2[:,:,c,a])\n",
    "                Z2[i,a] = np.exp(np.sum(A) + b2[:,:,:,a])\n",
    "        s = np.sum(Z2[i,:])\n",
    "        Z2[i,:]=Z2[i,:]/s\n",
    "        S[i]=s\n",
    "    cache['S']=S\n",
    "    cache['Z2']=Z2\n",
    "    print(\" Fully connected forward pass done\")\n",
    "    return(cache)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def back_prop(cache,Y):\n",
    "    \"\"\"\n",
    "    Updates the weights using simple backpropagation\n",
    "    \n",
    "    Arguments:\n",
    "    E -- error output, numpy array of shape (m,n_F)\n",
    "    Y -- Binary actual output\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #Import all saved data from cache\n",
    "    S = cache['S']\n",
    "    X_pad = cache['X_pad']\n",
    "    W2 = cache['W2']\n",
    "    R_Z = cache['R_Z']\n",
    "    Z = cache['Z']\n",
    "    W = cache['W']\n",
    "    b = cache['b']\n",
    "    W2 = cache['W2']\n",
    "    b2 = cache['b2']\n",
    "    m = Z.shape[0]\n",
    "    \n",
    "    #Initialize all weight and bias updates\n",
    "    dW2 = np.zeros((n_H2,n_W2,n_f,n_F))\n",
    "    db2 = np.zeros((1,1,1,n_F))\n",
    "    dW = np.zeros((f_H,f_W,n_C,n_f))\n",
    "    db = np.zeros((1,1,1,n_f))\n",
    "    \n",
    "    \n",
    "    for a in range(n_F):\n",
    "        for i in range(m): #Loopover images\n",
    "            Xc = X_pad[i]\n",
    "            dW2[:,:,:,a] += (-lr/m) * (Z[i,:,:,:]) * (Y[i,a]) * (S[i])\n",
    "            db2[:,:,:,a] += (-lr/m) * (Y[i,a]) * (S[i])\n",
    "            \n",
    "            for c in range(n_f): #Loop over\n",
    "                for h in range(n_H2):\n",
    "                    for w in range(n_W2):\n",
    "                         \n",
    "                            \n",
    "                        # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                        vert_start = h*stride\n",
    "                        vert_end = vert_start+f_H\n",
    "                        horiz_start = w*stride\n",
    "                        horiz_end = horiz_start+f_W\n",
    "                        X_slice = Xc[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                        \n",
    "                        dW[:,:,:,c] += (-lr/m) * Y[i,a] * S[i] * W2[h,w,c,a] * R_Z[i,h,w,c] * X_slice\n",
    "                        db[:,:,:,c] += (-lr/m) * Y[i,a] * S[i] * W2[h,w,c,a] * R_Z[i,h,w,c]\n",
    "                        \n",
    "    W2 += dW2\n",
    "    b2 += db2\n",
    "    W += dW\n",
    "    b += db\n",
    "    cache['W']=W\n",
    "    cache['b']=b\n",
    "    cache['W2']=W2\n",
    "    cache['b2']=b2\n",
    "    print(\"Backprop done, parameters updated\")\n",
    "    return cache\n",
    "            \n",
    "                               \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(Z2,Y):\n",
    "    \"\"\"\n",
    "    Gets total cross entropy loss for binary output Y\n",
    "    \n",
    "    Arguments:\n",
    "    Z2 -- fully connected output, numpy array of shape (m, n_F)\n",
    "    Y -- Binary actual output, numpy array of shape (m,n_F)\n",
    "    \n",
    "    Returns:\n",
    "    E -- error output\n",
    "    \"\"\"\n",
    "    E=0 \n",
    "    for a in range(n_F):\n",
    "        e=0\n",
    "        for i in range(m):\n",
    "            e += - Y[i,a]*np.log(Z2[i,a])\n",
    "        e=e/m\n",
    "        E+=e\n",
    "    return(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_pass(X,cache,Y):\n",
    "    cache = conv_forward(X,cache)\n",
    "    cache = fully_connected(cache)\n",
    "    print(\" Cross entropy loss is:\",cross_entropy_loss(cache['Z2'],Y))\n",
    "    cache = back_prop(cache,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Convolutional forward pass done\n",
      " Fully connected forward pass done\n",
      " Cross entropy loss is: 247.177687876\n",
      "Backprop done, parameters updated\n",
      " Convolutional forward pass done\n",
      " Fully connected forward pass done\n",
      " Cross entropy loss is: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "#Setting number of images\n",
    "m = 100 \n",
    "\n",
    "#random input data\n",
    "X = np.random.randn(m,n_H,n_W,n_C)\n",
    "\n",
    "#random output data\n",
    "Y = np.zeros((m,n_F)) \n",
    "Y[0:50,0:5]=np.ones((50,5))\n",
    "Y[0:50,5:]=np.ones((50,5))\n",
    "\n",
    "cache['W'] = np.random.randn(f_H, f_W,n_C,n_f)\n",
    "cache['b'] = np.random.randn(1,1,1,n_f)\n",
    "cache['W2'] = np.random.randn(n_H2,n_W2,n_f,n_F)\n",
    "cache['b2'] = np.random.randn(1,1,1,n_F)\n",
    "\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    forward_pass(X,cache,Y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
